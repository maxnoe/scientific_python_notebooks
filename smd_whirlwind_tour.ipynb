{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMD Python Hands On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warum python?\n",
    "\n",
    "<img alt=\"stackoverflow\" src=\"https://zgab33vy595fw5zq-zippykid.netdna-ssl.com/wp-content/uploads/2017/09/growth_major_languages-1-1024x878.png\" width=\"600px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlagen\n",
    "\n",
    "Werden heute hier nicht besprochen, gute Einstiegspunkte sind:\n",
    "\n",
    "* [PeP et al. Toolbox Workshop](https://toolbox.pep-dortmund.org)\n",
    "* [The scientific Python lectures](https://github.com/jrjohansson/scientific-python-lectures)\n",
    "* [A Byte Of Python](https://python.swaroopch.com/)\n",
    "\n",
    "Insbesondere für den Hauptteil der Vorlesung:\n",
    "* [The Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Guide und Linter\n",
    "\n",
    "* Für python gibt es einen allgemein annerkannte Style Guide, pep8. Beachten!\n",
    "\n",
    "* `conda install flake8 pyflakes pycodestyle`\n",
    "\n",
    "    * `pycodestyle test.py`\n",
    "    * `pyflakes test.py`\n",
    "    * `flake8 test.py`\n",
    "\n",
    "* Alle vernünftigen Editoren können Fehler und Nichtbefolgung eines Style Guides markieren (Linting).\n",
    "  * VS Code Plugin: https://marketplace.visualstudio.com/items?itemName=ms-python.python\n",
    "  * Atom-Plugin: https://atom.io/packages/linter-flake8\n",
    "  * Vim-Plugins: https://github.com/neomake/neomake oder https://github.com/vim-syntastic/syntastic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy\n",
    "\n",
    "Wiederholdung der wichtigsten numpy Eigenschaften.\n",
    "\n",
    "* Schnell durch Vektorisierung und kompilierten C++/C/Fortran-Code  \n",
    "   ⇒ Keine Python Schleifen über numpy arrays\n",
    "* Viele Funktionen für Datenanalyse, Zufallszahlen, Numerik, Lineare Algebra etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indizierung & Masken\n",
    "\n",
    "Indizierung über Slices und/oder boolean Masken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klammern wichtig\n",
    "# | = or\n",
    "# & = and\n",
    "# ~ = not\n",
    "\n",
    "a[(a > -1) & (a < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and(a > -1, a < 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das axis keyword\n",
    "\n",
    "Wichtig für aggregierende Operationen (z.B. `np.sum`, `np.mean`, `np.prod`, `np.std`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(12).reshape(4, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Arrays verschiedener Größe miteinander verrechnen, wo es geht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape(4, 3)\n",
    "b = 5\n",
    "c = np.arange(3)\n",
    "d = np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a - d -> error\n",
    "(a.T - d).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Beispiel: Loops vs. Numpy vektorisiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe: Rechne den Punkt mit dem kleinsten Abstand zu einem anderen Punkt aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = (0, 1)\n",
    "points = [\n",
    "    (0, 0),\n",
    "    (0.5, -0.5),\n",
    "    (1, -1),\n",
    "    (0, 2),\n",
    "    (0, 1.1),\n",
    "    (-2, 3),\n",
    "    (5, 1),\n",
    "    (10, 4),\n",
    "    (-4, 2),\n",
    "    (-3, 0),\n",
    "] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure Python Lösung mit loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(points, point):\n",
    "    min_distance = float('inf')\n",
    "    for i, other in enumerate(points):\n",
    "        distance = ((other[0] - point[0])**2 + (other[1] - point[1])**2)**0.5\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_idx = i\n",
    "    \n",
    "    return min_idx\n",
    "\n",
    "idx = find_closest(points, point)\n",
    "print(idx, points[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "find_closest(points, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(points)\n",
    "point = np.array(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_numpy(points, point):\n",
    "    distances = np.linalg.norm(points - point, axis=1)\n",
    "    idx = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "idx = find_closest_numpy(points, point)\n",
    "print(idx, points[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "find_closest_numpy(points, point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = np.random.uniform(-5, 5, 1000)\n",
    "gaussian = np.random.normal(0, 1, 1000)\n",
    "poisson = np.random.poisson(3, 1000)\n",
    "\n",
    "mean = [2, 1]\n",
    "cov = [[2, 1],\n",
    "       [1, 4]]\n",
    "gauss_2d = np.random.multivariate_normal(mean, cov, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für reproduzierbarkeit wichtig: der Startwert (seed) des Zufallszahlengenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matplotlib\n",
    "\n",
    "Die zwei wichtigsten Plot-Arten für die Datenanalyse sind Histogramme und Streudiagramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (12, 8), 'font.size': 12})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gaussian, bins=20, range=[-5, 5])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Vergleichen ist es wichtig, das gleiche Binning zu verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gaussian, bins=20, range=[-5, 5], histtype='step', label='Gaussian')\n",
    "plt.hist(uniform, bins=20, range=[-5, 5], histtype='step', label='Uniform')\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bei diskreten Werten unbedingt ganzzahlige, zentrierte bins verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(poisson, bins=15)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(poisson, bins=np.arange(15) - 0.5, edgecolor='w') # bins kann entweder Anzahl oder Grenzen sein\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gauss_2d[:, 0], gauss_2d[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_2d = np.random.multivariate_normal(mean, cov, 10000)\n",
    "plt.scatter(gauss_2d[:, 0], gauss_2d[:, 1], s=5, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scatter kann ein Drittes Attribut als Farbe darstellen\n",
    "* Mit ListedColorMap bekommt man eine diskrete Colormap mit einer Farbe für jede Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ColorMap mit N diskreten Farben aus der\n",
    "# matplotlib Farb rotation, 'C0', 'C1', ... \n",
    "cmap = ListedColormap([\n",
    "    'C{}'.format(i) \n",
    "    for i in range(len(iris.target_names))\n",
    "])\n",
    "\n",
    "plt.scatter(\n",
    "    iris.data[:, 0],  # x-werte, erste Spalte\n",
    "    iris.data[:, 1],  # y-werte, zweite Spalte \n",
    "    c=iris.target,    # Farbachse, Sorte\n",
    "    cmap=cmap,        # colormap, siehe oben\n",
    "    vmin=-0.5,        # Minimum der Farbachse\n",
    "    vmax=len(iris.target_names) - 0.5,  # Maximimum der Farbachse\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "\n",
    "bar = plt.colorbar(ticks=[0, 1, 2])\n",
    "bar.set_ticklabels(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(\n",
    "    gauss_2d[:, 0],\n",
    "    gauss_2d[:, 1],\n",
    "    bins=[20, 20],\n",
    "    range=[[-3, 7], [-7, 9]]\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchmal hilfreich: Logarithmische Skala auf der Farbachse\n",
    "\n",
    "z.B. um eine zweite, kleine Population zu erkennen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_2d = np.random.multivariate_normal(mean, cov, 100000)\n",
    "gauss_2d_2 = np.random.multivariate_normal([-1.5, 4.5], [[0.5, 0], [0, 0.5]], 500)\n",
    "\n",
    "gauss_2d_both = np.concatenate([gauss_2d, gauss_2d_2], axis=0)\n",
    "\n",
    "gauss_2d_both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(\n",
    "    gauss_2d_both[:, 0],\n",
    "    gauss_2d_both[:, 1],\n",
    "    bins=[50, 50],\n",
    "    range=[[-3, 7], [-7, 9]]\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.hist2d(\n",
    "    gauss_2d_both[:, 0],\n",
    "    gauss_2d_both[:, 1],\n",
    "    bins=[50, 50],\n",
    "    range=[[-3, 7], [-7, 9]],\n",
    "    norm=LogNorm(),\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy\n",
    "\n",
    "Für SMD werden vor allem das `scipy.optimize` und das `scipy.stats` Modul wichtig werden\n",
    "\n",
    "### scipy.stats\n",
    "\n",
    "Viele Statistische Verteilungen, Likelihood-Fits eingebaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mean = 5\n",
    "std = 2\n",
    "\n",
    "x = np.linspace(mean - 5 * std, mean + 5 * std, 250)\n",
    "\n",
    "gaussian = norm(mean, std)\n",
    "samples = gaussian.rvs(size=1000)\n",
    "\n",
    "plt.plot(x, gaussian.pdf(x), label='Wahrscheinlichkeitsdichte')\n",
    "plt.plot(x, gaussian.cdf(x), label='Verteilungsfunktion')\n",
    "\n",
    "\n",
    "# In matplotlib < 2.1 hieß `density` `normed`\n",
    "plt.hist(\n",
    "    samples,\n",
    "    bins=100,\n",
    "    range=[x.min(), x.max()],\n",
    "    density=True,  # Fläche des Histogramms soll 1 sein\n",
    "    label='Normiertes Histogramm',\n",
    ")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = norm(5, 1).rvs(100)\n",
    "\n",
    "norm.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.optimize\n",
    "\n",
    "Ihr kennt alle `curve_fit` aus dem Praktikum, `scipy` kann mehr:\n",
    "* Nullstellen finden\n",
    "* Allgemeine Funktionen minimiere (mit Randbedingungen)\n",
    "* (Unterbestimmte) Gleichungssysteme Lösen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nullstellen & Minima\n",
    "\n",
    "Genauere Informationen siehe Docs der einzelnen Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import newton, brentq, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x - 5)**2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nullstellen\n",
    "\n",
    "x0_1 = newton(f, 1)\n",
    "x0_2 = newton(f, 8)\n",
    "\n",
    "x0_1, x0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum\n",
    "\n",
    "result = minimize(f, x0=(2))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = result.x\n",
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(2, 8, 250)\n",
    "plt.plot(x, f(x))\n",
    "plt.grid()\n",
    "\n",
    "plt.axvline(x0_1, color='C1', label='Nullstelle 1')\n",
    "plt.axvline(x0_2, color='C2', label='Nullstelle 2')\n",
    "plt.axvline(minimum, color='C3', label='Minimum')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood-Fit (Mehr dazu später in der Vorlesung)\n",
    "\n",
    "Beispiel Higgs Messung\n",
    "\n",
    "Wir haben Normal-Verteiltes Signal der Higgs-Masse und Exponentiell verteilten Untergrund und möchten\n",
    "die Higgs-Masse mit einem Fit bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "e_min = 75\n",
    "e_max = 175\n",
    "\n",
    "higgs_signal = np.random.normal(126, 5, 500)\n",
    "background = np.random.exponential(50, size=20000)\n",
    "background = background[(background > e_min) & (background < e_max)]\n",
    "\n",
    "measured = np.append(higgs_signal, background)\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(measured, bins=100)\n",
    "plt.xlabel('$m / \\mathrm{GeV}$')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, expon\n",
    "\n",
    "\n",
    "def pdf(x, mean, std, tau, p, e_min, e_max):\n",
    "    N = np.exp(-e_min / tau) - np.exp(-e_max / tau)\n",
    "    return (\n",
    "        p * norm.pdf(x, mean, std) \n",
    "        + (1 - p) / N * expon.pdf(x, scale=tau)\n",
    "    )\n",
    "\n",
    "def neg_log_likelihood(params, data, e_min, e_max):\n",
    "    return -np.sum(np.log(pdf(data, *params, e_min=e_min, e_max=e_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(\n",
    "    neg_log_likelihood,\n",
    "    x0=(130, 2, 30, 0.2),\n",
    "    bounds=[\n",
    "        (None, None), # No bounds for mean\n",
    "        (1e-30, None), # std > 0\n",
    "        (1e-30, None), # tau > 0\n",
    "        (0, 1), # 0 <= p <= 1\n",
    "    ],\n",
    "    args=(measured, e_min, e_max)\n",
    ")\n",
    "\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Higgs mass is {} ± {} GeV'.format(result.x[0], np.sqrt(result.hess_inv.todense()[0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cov = result.hess_inv.todense()\n",
    "A = np.diag(1 / np.sqrt(np.diag(cov)))\n",
    "\n",
    "cor = A @ cov @ A.T\n",
    "\n",
    "plt.matshow(cor, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "plt.xticks(np.arange(4), ['mean', 'std', 'tau', 'p'])\n",
    "plt.yticks(np.arange(4), ['mean', 'std', 'tau', 'p'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, edges, plot = plt.hist(measured, bins=100)\n",
    "m = np.linspace(e_min, e_max, 250)\n",
    "plt.plot(m, pdf(m, *result.x, e_min, e_max) * np.diff(edges)[0] * len(measured))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas\n",
    "\n",
    "Docu: [Hier](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "\n",
    "Bibliothek für Datenanalyse, zentrales Konzept: `pd.DataFrame` → 2d-Tabelle aus Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = pd.DataFrame({\n",
    "    'x': np.random.normal(0, 1, 1000),\n",
    "    'y': np.random.normal(0, 1, 1000),\n",
    "    'N': np.random.poisson(20, 1000),\n",
    "    't': np.random.exponential(5, 1000),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.plot.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal['t'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 is a fast, binary format\n",
    "signal.to_hdf('data.hdf5', key='signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = pd.DataFrame({\n",
    "    'x': np.random.uniform(-4, 4, 10000),\n",
    "    'y': np.random.uniform(-4, 4, 10000),\n",
    "    'N': np.random.poisson(30, 10000),\n",
    "    't': np.random.exponential(10, 10000),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mehrere DataFrames in einer Datei speichern\n",
    "background.to_hdf('data.hdf5', key='background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('data.hdf5', key='signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first / last values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie viele Valide Werte gibt es in jeder Spalte?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spalten loswerden, die zu viele missing values haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=1 Spalten droppen\n",
    "# inplace=df direkt bearbeiten\n",
    "df.drop(['cabin', 'boat', 'body', 'home.dest'], axis=1, inplace=True) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie war die Geschlechter Verteilung auf der Titanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mächtige Operation: GroupBy → Aggregate\n",
    "\n",
    "Datensatz in mehrere Gruppen unterteilen und pro Gruppe zusammenfassen.\n",
    "\n",
    "Hier: Aufgeschlüsselt nach Geschlecht, den Prozentsatz der überlebenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sex')['survived'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch DataFrames unterstützen masken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['child'] = df.age < 9\n",
    "\n",
    "df[df.child].survived.mean(), df[~df.child].survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('child').survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joblib\n",
    "\n",
    "Einfaches tool um Sachen Parallel zu machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import random\n",
    "\n",
    "def long_running_calculation(num):\n",
    "    sleep(random.random())\n",
    "    return num**2\n",
    "\n",
    "\n",
    "with Parallel(n_jobs=4, verbose=10) as pool:\n",
    "    result = pool(delayed(long_running_calculation)(i) for i in range(100))\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
